import os
import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

from src.embeddings.embedder import EmbedderFactory
from src.preprocessing.preprocessor_factory import PreprocessorFactory
from src.storage.storage import FAISSStorage
import tempfile

from config.logging_config import configure_logging

configure_logging()


def recursive_files_scan(directory: Path):
    directory = Path(directory)
    for item in directory.iterdir():
        if item.is_file():
            yield item
        elif item.is_dir():
            yield from recursive_files_scan(item)


def test_storage_basic():
    """–ë–∞–∑–æ–≤–∏–π —Ç–µ—Å—Ç: add, search, save, load"""

    print("=" * 60)
    print("–¢–ï–°–¢ 1: –ë–∞–∑–æ–≤–∏–π —Ñ—É–Ω–∫—Ü—ñ–æ–Ω–∞–ª Storage")
    print("=" * 60)

    # 1. –°—Ç–≤–æ—Ä—é—î–º–æ storage
    storage = FAISSStorage(dimension=384)
    print(f"‚úÖ Storage —Å—Ç–≤–æ—Ä–µ–Ω–æ: {storage.get_stats()}\n")

    prep = PreprocessorFactory.create(worker="minimal",
                                      default_parser="pdf_marker")
    embedder = EmbedderFactory.create("sbert")

    file_name = "JIRACORESERVER0"
    path = f"data\\raw\\{file_name}.pdf"

    folder = "python-3.13.8-docs-text"

    # for file in recursive_files_scan("data\\raw\\" + folder):
    # res = prep.process_document(file)
    # vector_res = embedder.embed_batch(res.chunks)
    # storage.add(vector_res, res.chunks)

    res = prep.process_document(path)
    vector_res = embedder.embed_batch(res.chunks)
    storage.add(vector_res, res.chunks)

    # 3. –î–æ–¥–∞—î–º–æ –≤ storage
    stats = storage.get_stats()
    print(f"‚úÖ –í–µ–∫—Ç–æ—Ä–∏ –¥–æ–¥–∞–Ω–æ –≤ —ñ–Ω–¥–µ–∫—Å:")
    print(f"   Total vectors: {stats['total_vectors']}")

    # 4. –ü–æ—à—É–∫
    query_vector = vector_res[0].vector  # –®—É–∫–∞—î–º–æ –ø–µ—Ä—à–∏–π –≤–µ–∫—Ç–æ—Ä
    results = storage.search(query_vector, top_k=3)

    print(f"‚úÖ –ü–æ—à—É–∫ –≤–∏–∫–æ–Ω–∞–Ω–æ, –∑–Ω–∞–π–¥–µ–Ω–æ {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤:")
    for i, result in enumerate(results):
        print(f"   {i+1}. Score: {result.score:.4f}, Chunk: {result.chunk_id}")
        print(f"       Text: {result.chunk.text[:80]}...")
    print()

    # 5. –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è
    with tempfile.TemporaryDirectory() as tmpdir:
        save_path = Path("data\\processed\\") / "test_index"
        storage.save(str(save_path))
        print(f"‚úÖ –Ü–Ω–¥–µ–∫—Å –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {save_path}\n")

        # 6. –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è
        new_storage = FAISSStorage(dimension=384)
        new_storage.load(str(save_path))
        print(f"‚úÖ –Ü–Ω–¥–µ–∫—Å –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ")
        print(f"   Stats: {new_storage.get_stats()}\n")

        # 7. –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –ø—ñ—Å–ª—è –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è
        results2 = new_storage.search(query_vector, top_k=3)
        print(f"‚úÖ –ü–æ—à—É–∫ –ø—ñ—Å–ª—è –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è:")
        for i, result in enumerate(results2):
            print(
                f"   {i+1}. Score: {result.score:.4f}, Chunk: {result.chunk_id}"
            )
            print(f"       Text: {result.chunk.text[:80]}...")
        print()

        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —â–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –æ–¥–Ω–∞–∫–æ–≤—ñ
        assert len(results) == len(
            results2), "–ö—ñ–ª—å–∫—ñ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –Ω–µ —Å–ø—ñ–≤–ø–∞–¥–∞—î!"
        for r1, r2 in zip(results, results2):
            assert r1.chunk_id == r2.chunk_id, "Chunk ID –Ω–µ —Å–ø—ñ–≤–ø–∞–¥–∞—î!"
            assert abs(r1.score - r2.score) < 0.001, "Score –Ω–µ —Å–ø—ñ–≤–ø–∞–¥–∞—î!"

        print("‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –ø—ñ—Å–ª—è –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Å–ø—ñ–≤–ø–∞–¥–∞—é—Ç—å!")

    print("\nüéâ –¢–µ—Å—Ç –ø—Ä–æ–π–¥–µ–Ω–æ —É—Å–ø—ñ—à–Ω–æ!\n")


if __name__ == "__main__":
    test_storage_basic()
