"""
–¢–µ—Å—Ç–∏ –¥–ª—è AIAgent
"""
import sys
from pathlib import Path
import os
import logging

sys.path.insert(0, str(Path(__file__).parent.parent))

from src.agent.agent import AIAgent
from src.storage.storage import FAISSStorage
from src.preprocessing.preprocessor import Preprocessor
from src.embeddings.embedder import EmbedderFactory
from src.agent.llm_client import LLMClientFactory

logger = logging.getLogger(__name__)


def test_agent_with_mock_data():
    """–¢–µ—Å—Ç AIAgent –∑ —Å–∏–º—É–ª—å–æ–≤–∞–Ω–∏–º–∏ –¥–∞–Ω–∏–º–∏"""
    print("=" * 70)
    print("–¢–ï–°–¢ AIAGENT")
    print("=" * 70)

    # –í–ê–ñ–õ–ò–í–û: –í—Å—Ç–∞–Ω–æ–≤—ñ—Ç—å –≤–∞—à API –∫–ª—é—á
    PERPLEXITY_API_KEY = os.getenv("PERPLEXITY_API_KEY", "your-api-key-here")

    if PERPLEXITY_API_KEY == "your-api-key-here":
        print("‚ö†Ô∏è  –£–í–ê–ì–ê: –í—Å—Ç–∞–Ω–æ–≤—ñ—Ç—å PERPLEXITY_API_KEY environment variable!")
        print("export PERPLEXITY_API_KEY='your-key'")
        return

    # 1. –°—Ç–≤–æ—Ä—é—î–º–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏
    print("\n1Ô∏è‚É£ –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ñ–≤...")

    storage = FAISSStorage(dimension=384)
    embedder = EmbedderFactory.create(method="sbert")
    llm_client = LLMClientFactory.create(
        provider="perplexity",
        api_key=PERPLEXITY_API_KEY,
        model="sonar"  # –ï–∫–æ–Ω–æ–º–Ω–∞ –º–æ–¥–µ–ª—å
    )

    # 2. –î–æ–¥–∞—î–º–æ —Ç–µ—Å—Ç–æ–≤—ñ –¥–æ–∫—É–º–µ–Ω—Ç–∏
    print("2Ô∏è‚É£ –Ü–Ω–¥–µ–∫—Å–∞—Ü—ñ—è —Ç–µ—Å—Ç–æ–≤–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤...")

    preprocessor = Preprocessor()

    file_name = "introduction_to_microservices_galkin_shkilniak"
    path = f"data\\raw\\{file_name}.pdf"
    result = preprocessor.process_document(path)

    test_chunks = result.chunks

    # –í–µ–∫—Ç–æ—Ä–∏–∑—É—î–º–æ —ñ –¥–æ–¥–∞—î–º–æ –≤ storage
    embeddings = embedder.embed_batch(test_chunks)
    storage.add(embeddings, result.chunks)

    print(f"   ‚úÖ –î–æ–¥–∞–Ω–æ {len(test_chunks)} –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤")

    # 3. –°—Ç–≤–æ—Ä—é—î–º–æ AIAgent
    print("3Ô∏è‚É£ –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è AIAgent...")

    agent = AIAgent(storage=storage,
                    embedder=embedder,
                    llm_client=llm_client,
                    top_k=3,
                    min_similarity=0.2,
                    temperature=0.1,
                    max_tokens=300,
                    language="uk")

    print("   ‚úÖ AIAgent –≥–æ—Ç–æ–≤–∏–π\n")

    # 4. –¢–µ—Å—Ç–æ–≤—ñ –∑–∞–ø–∏—Ç–∏
    test_queries = [
        "–©–æ —Ç–∞–∫–µ –º—ñ–∫—Ä–æ—Å–µ—Ä–≤—ñ—Å–∏?", "–Ø–∫—ñ –±—É–≤–∞—é—Ç—å —à–∞–±–ª–æ–Ω–∏ –º—ñ–∫—Ä–æ—Å–µ—Ä–≤—ñ—Å—ñ–≤?"
    ]

    print("4Ô∏è‚É£ –û–±—Ä–æ–±–∫–∞ —Ç–µ—Å—Ç–æ–≤–∏—Ö –∑–∞–ø–∏—Ç—ñ–≤:\n")
    print("=" * 70)

    for i, query in enumerate(test_queries, 1):
        print(f"\nüìù –ó–∞–ø–∏—Ç {i}: {query}")
        print("-" * 70)

        # –û—Ç—Ä–∏–º—É—î–º–æ –≤—ñ–¥–ø–æ–≤—ñ–¥—å
        response = agent.answer(query)

        # –í–∏–≤–æ–¥–∏–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        print(f"\nüí° –í—ñ–¥–ø–æ–≤—ñ–¥—å:\n{response.answer}\n")

        print(f"üìö –î–∂–µ—Ä–µ–ª–∞ ({len(response.sources)}):")
        for j, source in enumerate(response.sources, 1):
            print(
                f"  [{j}] Score: {source.score:.3f} | {source.chunk.text[:60]}..."
            )

        print(f"\nüìä –ú–µ—Ç–∞–¥–∞–Ω—ñ: {response.metadata}")
        print("=" * 70)

    print("\nüéâ –¢–µ—Å—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø—ñ—à–Ω–æ!")


if __name__ == "__main__":
    test_agent_with_mock_data()
