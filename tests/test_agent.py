"""
–¢–µ—Å—Ç–∏ –¥–ª—è AIAgent
"""
import sys
from pathlib import Path
import os

sys.path.insert(0, str(Path(__file__).parent.parent))

from src.agent.agent import AIAgent
from src.storage.storage import FAISSStorage
from src.embeddings.embedder import EmbedderFactory
from src.agent.llm_client import LLMClientFactory
from src.models import EmbedderResult, TextChunk
import numpy as np


def test_agent_with_mock_data():
    """–¢–µ—Å—Ç AIAgent –∑ —Å–∏–º—É–ª—å–æ–≤–∞–Ω–∏–º–∏ –¥–∞–Ω–∏–º–∏"""
    print("=" * 70)
    print("–¢–ï–°–¢ AIAGENT")
    print("=" * 70)

    # –í–ê–ñ–õ–ò–í–û: –í—Å—Ç–∞–Ω–æ–≤—ñ—Ç—å –≤–∞—à API –∫–ª—é—á
    PERPLEXITY_API_KEY = os.getenv("PERPLEXITY_API_KEY", "your-api-key-here")

    if PERPLEXITY_API_KEY == "your-api-key-here":
        print("‚ö†Ô∏è  –£–í–ê–ì–ê: –í—Å—Ç–∞–Ω–æ–≤—ñ—Ç—å PERPLEXITY_API_KEY environment variable!")
        print("export PERPLEXITY_API_KEY='your-key'")
        return

    # 1. –°—Ç–≤–æ—Ä—é—î–º–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏
    print("\n1Ô∏è‚É£ –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ñ–≤...")

    storage = FAISSStorage(dimension=384)
    embedder = EmbedderFactory.create(method="sbert")
    llm_client = LLMClientFactory.create(
        provider="perplexity",
        api_key=PERPLEXITY_API_KEY,
        model="sonar"  # –ï–∫–æ–Ω–æ–º–Ω–∞ –º–æ–¥–µ–ª—å
    )

    # 2. –î–æ–¥–∞—î–º–æ —Ç–µ—Å—Ç–æ–≤—ñ –¥–æ–∫—É–º–µ–Ω—Ç–∏
    print("2Ô∏è‚É£ –Ü–Ω–¥–µ–∫—Å–∞—Ü—ñ—è —Ç–µ—Å—Ç–æ–≤–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤...")

    test_chunks = [
        TextChunk(
            text=
            "–ú–∞—à–∏–Ω–Ω–µ –Ω–∞–≤—á–∞–Ω–Ω—è ‚Äî —Ü–µ –ø—ñ–¥–≥–∞–ª—É–∑—å —à—Ç—É—á–Ω–æ–≥–æ —ñ–Ω—Ç–µ–ª–µ–∫—Ç—É, —è–∫–∞ –¥–æ–∑–≤–æ–ª—è—î –∫–æ–º–ø'—é—Ç–µ—Ä–∞–º –≤—á–∏—Ç–∏—Å—è –Ω–∞ –¥–∞–Ω–∏—Ö –±–µ–∑ —è–≤–Ω–æ–≥–æ –ø—Ä–æ–≥—Ä–∞–º—É–≤–∞–Ω–Ω—è. –°–∏—Å—Ç–µ–º–∏ ML –∞–Ω–∞–ª—ñ–∑—É—é—Ç—å –ø–∞—Ç–µ—Ä–Ω–∏ —Ç–∞ –ø—Ä–∏–π–º–∞—é—Ç—å —Ä—ñ—à–µ–Ω–Ω—è.",
            chunk_id="chunk_1",
            document_id="doc_ml",
            chunk_index=0),
        TextChunk(
            text=
            "Python —î –Ω–∞–π–ø–æ–ø—É–ª—è—Ä–Ω—ñ—à–æ—é –º–æ–≤–æ—é –¥–ª—è data science —Ç–∞ –º–∞—à–∏–Ω–Ω–æ–≥–æ –Ω–∞–≤—á–∞–Ω–Ω—è. –ë—ñ–±–ª—ñ–æ—Ç–µ–∫–∏ —è–∫ NumPy, Pandas —Ç–∞ Scikit-learn –Ω–∞–¥–∞—é—Ç—å –ø–æ—Ç—É–∂–Ω—ñ —ñ–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∏ –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É –¥–∞–Ω–∏—Ö.",
            chunk_id="chunk_2",
            document_id="doc_python",
            chunk_index=0),
        TextChunk(
            text=
            "–¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∏ —Ä–µ–≤–æ–ª—é—Ü—ñ–æ–Ω—ñ–∑—É–≤–∞–ª–∏ –æ–±—Ä–æ–±–∫—É –ø—Ä–∏—Ä–æ–¥–Ω–æ—ó –º–æ–≤–∏. –ú–µ—Ö–∞–Ω—ñ–∑–º attention –¥–æ–∑–≤–æ–ª—è—î –º–æ–¥–µ–ª—ñ —Ñ–æ–∫—É—Å—É–≤–∞—Ç–∏—Å—è –Ω–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∏—Ö —á–∞—Å—Ç–∏–Ω–∞—Ö –≤—Ö—ñ–¥–Ω–∏—Ö –¥–∞–Ω–∏—Ö.",
            chunk_id="chunk_3",
            document_id="doc_transformers",
            chunk_index=0)
    ]

    # –í–µ–∫—Ç–æ—Ä–∏–∑—É—î–º–æ —ñ –¥–æ–¥–∞—î–º–æ –≤ storage
    embeddings = embedder.embed_batch(test_chunks)
    storage.add(embeddings)

    print(f"   ‚úÖ –î–æ–¥–∞–Ω–æ {len(test_chunks)} –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤")

    # 3. –°—Ç–≤–æ—Ä—é—î–º–æ AIAgent
    print("3Ô∏è‚É£ –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è AIAgent...")

    agent = AIAgent(storage=storage,
                    embedder=embedder,
                    llm_client=llm_client,
                    top_k=3,
                    min_similarity=0.2,
                    temperature=0.1,
                    max_tokens=300,
                    language="uk")

    print("   ‚úÖ AIAgent –≥–æ—Ç–æ–≤–∏–π\n")

    # 4. –¢–µ—Å—Ç–æ–≤—ñ –∑–∞–ø–∏—Ç–∏
    test_queries = [
        "–©–æ —Ç–∞–∫–µ –º–∞—à–∏–Ω–Ω–µ –Ω–∞–≤—á–∞–Ω–Ω—è?", "–Ø–∫–∞ –º–æ–≤–∞ –ø—Ä–æ–≥—Ä–∞–º—É–≤–∞–Ω–Ω—è –Ω–∞–π–∫—Ä–∞—â–∞ –¥–ª—è ML?",
        "–Ø–∫ –ø—Ä–∞—Ü—é—é—Ç—å —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∏?"
    ]

    print("4Ô∏è‚É£ –û–±—Ä–æ–±–∫–∞ —Ç–µ—Å—Ç–æ–≤–∏—Ö –∑–∞–ø–∏—Ç—ñ–≤:\n")
    print("=" * 70)

    for i, query in enumerate(test_queries, 1):
        print(f"\nüìù –ó–∞–ø–∏—Ç {i}: {query}")
        print("-" * 70)

        # –û—Ç—Ä–∏–º—É—î–º–æ –≤—ñ–¥–ø–æ–≤—ñ–¥—å
        response = agent.answer(query)

        # –í–∏–≤–æ–¥–∏–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        print(f"\nüí° –í—ñ–¥–ø–æ–≤—ñ–¥—å:\n{response.answer}\n")

        print(f"üìö –î–∂–µ—Ä–µ–ª–∞ ({len(response.sources)}):")
        for j, source in enumerate(response.sources, 1):
            print(
                f"  [{j}] Score: {source.score:.3f} | {source.chunk.text[:60]}..."
            )

        print(f"\nüìä –ú–µ—Ç–∞–¥–∞–Ω—ñ: {response.metadata}")
        print("=" * 70)

    print("\nüéâ –¢–µ—Å—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø—ñ—à–Ω–æ!")


if __name__ == "__main__":
    test_agent_with_mock_data()
