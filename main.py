import argparse
import logging
from pathlib import Path

from src.preprocessing.preprocessor import Preprocessor
from src.embeddings.embedder import EmbedderFactory
from src.storage.storage import FAISSStorage

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def index_documents(input_path: str, output_path: str):
    """–Ü–Ω–¥–µ–∫—Å–∞—Ü—ñ—è –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤"""
    logger.info(f"–ü–æ—á–∞—Ç–æ–∫ —ñ–Ω–¥–µ–∫—Å–∞—Ü—ñ—ó –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤ –∑ {input_path}")

    # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ñ–≤
    preprocessor = Preprocessor()
    embedder = EmbedderFactory.create(method="sbert")
    storage = FAISSStorage(dimension=384)

    # –û–±—Ä–æ–±–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤
    pdf_files = list(Path(input_path).glob("*.pdf"))
    logger.info(f"–ó–Ω–∞–π–¥–µ–Ω–æ {len(pdf_files)} PDF —Ñ–∞–π–ª—ñ–≤")

    for pdf_file in pdf_files:
        try:
            logger.info(f"–û–±—Ä–æ–±–∫–∞: {pdf_file.name}")

            # Preprocessor + Chunking
            result = preprocessor.process_document(file_path=str(pdf_file),
                                                   enable_chunking=True,
                                                   chunk_size=500,
                                                   chunk_overlap=100)

            if not result.chunks:
                logger.warning(f"–ù–µ–º–∞—î —á–∞–Ω–∫—ñ–≤ –¥–ª—è {pdf_file.name}")
                continue

            # Embedding
            embeddings = embedder.embed_batch(result.chunks)

            # Storage
            storage.add(embeddings)

            logger.info(f"‚úÖ –û–±—Ä–æ–±–ª–µ–Ω–æ: {len(result.chunks)} —á–∞–Ω–∫—ñ–≤")

        except Exception as e:
            logger.error(f"–ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ {pdf_file.name}: {e}")

    # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —ñ–Ω–¥–µ–∫—Å—É
    storage.save(output_path)
    stats = storage.get_stats()
    logger.info(f"üìä –Ü–Ω–¥–µ–∫—Å –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {stats}")


def interactive_mode(index_path: str):
    """–Ü–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∏–π —Ä–µ–∂–∏–º –∑–∞–ø–∏—Ç—ñ–≤"""
    logger.info("–ó–∞–ø—É—Å–∫ —ñ–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–≥–æ —Ä–µ–∂–∏–º—É")

    # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —ñ–Ω–¥–µ–∫—Å—É
    embedder = EmbedderFactory.create(method="sbert")
    storage = FAISSStorage()
    storage.load(index_path)

    stats = storage.get_stats()
    logger.info(f"üìä –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ —ñ–Ω–¥–µ–∫—Å: {stats}")

    print("\n" + "=" * 60)
    print("RAG –°–ò–°–¢–ï–ú–ê - –Ü–ù–¢–ï–†–ê–ö–¢–ò–í–ù–ò–ô –†–ï–ñ–ò–ú")
    print("=" * 60)
    print("–í–≤–µ–¥—ñ—Ç—å –∑–∞–ø–∏—Ç–∞–Ω–Ω—è (–∞–±–æ 'exit' –¥–ª—è –≤–∏—Ö–æ–¥—É)\n")

    from src.models import TextChunk

    while True:
        query = input("–í–∞—à –∑–∞–ø–∏—Ç: ").strip()

        if query.lower() in ['exit', 'quit', '–≤–∏—Ö—ñ–¥']:
            break

        if not query:
            continue

        try:
            # –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü—ñ—è –∑–∞–ø–∏—Ç—É
            query_chunk = TextChunk(text=query,
                                    chunk_id="query",
                                    document_id="query")
            query_embedding = embedder.embed(query_chunk)

            # –ü–æ—à—É–∫
            results = storage.search(query_embedding.vector, top_k=3)

            print(f"\nüîç –ó–Ω–∞–π–¥–µ–Ω–æ {len(results)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∏—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ñ–≤:\n")
            for i, result in enumerate(results):
                print(f"{i+1}. Score: {result.score:.4f}")
                print(f"   {result.chunk.text[:200]}...")
                print(f"   (–î–æ–∫—É–º–µ–Ω—Ç: {result.document_id})\n")

        except Exception as e:
            logger.error(f"–ü–æ–º–∏–ª–∫–∞: {e}")

    print("–î–æ –ø–æ–±–∞—á–µ–Ω–Ω—è!")


def main():
    parser = argparse.ArgumentParser(description="RAG System")
    parser.add_argument("--mode",
                        choices=["index", "interactive"],
                        default="interactive",
                        help="–†–µ–∂–∏–º —Ä–æ–±–æ—Ç–∏")
    parser.add_argument("--input",
                        default="./data/documents",
                        help="–®–ª—è—Ö –¥–æ PDF –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤")
    parser.add_argument("--index-path",
                        default="./data/indexes/knowledge_base",
                        help="–®–ª—è—Ö –¥–æ —ñ–Ω–¥–µ–∫—Å—É")

    args = parser.parse_args()

    if args.mode == "index":
        index_documents(args.input, args.index_path)
    elif args.mode == "interactive":
        interactive_mode(args.index_path)


if __name__ == "__main__":
    main()
