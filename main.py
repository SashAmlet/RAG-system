import os
import argparse
from dotenv import load_dotenv
from rich.console import Console
from rich.markdown import Markdown
from pathlib import Path

from src.preprocessing.preprocessor_factory import PreprocessorFactory
from src.embeddings.embedder import EmbedderFactory
from src.storage.storage import FAISSStorage
from src.agent.agent import AIAgent
from src.agent.llm_client import LLMClientFactory

# –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –∑–º—ñ–Ω–Ω—ñ —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞
load_dotenv()

console = Console()


def index_documents(preprocessor, embedder, storage, data_dir="data/raw"):
    """–Ü–Ω–¥–µ–∫—Å—É—î –≤—Å—ñ –¥–æ–∫—É–º–µ–Ω—Ç–∏ –∑ –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—ó"""
    console.print(f"\n[bold blue]üìö –Ü–Ω–¥–µ–∫—Å–∞—Ü—ñ—è –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤ –∑ {data_dir}[/bold blue]\n")

    data_path = Path(data_dir)
    if not data_path.exists():
        console.print("[red]–î–∏—Ä–µ–∫—Ç–æ—Ä—ñ—è –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞![/red]")
        return

    files = list(data_path.glob("*.pdf")) + list(data_path.glob("*.txt"))

    if not files:
        console.print("[yellow]–î–æ–∫—É–º–µ–Ω—Ç–∏ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ![/yellow]")
        return

    all_chunks = []

    for file_path in files:
        console.print(f"üìÑ –û–±—Ä–æ–±–∫–∞: {file_path.name}")

        # –û–±—Ä–æ–±–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        result = preprocessor.process_document(
            str(file_path),
            enable_chunking=True,
            chunk_size=int(os.getenv("CHUNK_SIZE", 800)),
            chunk_overlap=int(os.getenv("CHUNK_OVERLAP", 150)),
        )

        console.print(f"   ‚úÖ –°—Ç–≤–æ—Ä–µ–Ω–æ {len(result.chunks)} —á–∞–Ω–∫—ñ–≤")
        all_chunks.extend(result.chunks)

    # –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü—ñ—è
    console.print(f"\nüî¢ –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü—ñ—è {len(all_chunks)} —á–∞–Ω–∫—ñ–≤...")
    embeddings = embedder.embed_batch(all_chunks)

    # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≤ storage
    console.print("üíæ –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É –ë–î...")
    storage.add(embeddings, all_chunks)
    storage.save("data/indexes/knowledge_base")

    stats = storage.get_stats()
    console.print(f"\n[bold green]‚úÖ –Ü–Ω–¥–µ–∫—Å–∞—Ü—ñ—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞![/bold green]")
    console.print(f"   –í–µ–∫—Ç–æ—Ä—ñ–≤: {stats['total_vectors']}")
    console.print(f"   –î–æ–∫—É–º–µ–Ω—Ç—ñ–≤: {stats['unique_documents']}\n")


def query_mode(agent):
    """–†–µ–∂–∏–º –æ–¥–∏–Ω–æ—á–Ω–æ–≥–æ –∑–∞–ø–∏—Ç—É"""
    question = input("\nüí¨ –í–∞—à–µ –∑–∞–ø–∏—Ç–∞–Ω–Ω—è: ")

    console.print("\n[yellow]ü§î –û–±—Ä–æ–±–∫–∞...[/yellow]\n")
    response = agent.answer(question)

    # –í–∏–≤–æ–¥–∏–º–æ –≤—ñ–¥–ø–æ–≤—ñ–¥—å
    console.print("[bold green]üí° –í—ñ–¥–ø–æ–≤—ñ–¥—å:[/bold green]")
    console.print(Markdown(response.answer))

    # –í–∏–≤–æ–¥–∏–º–æ –¥–∂–µ—Ä–µ–ª–∞
    console.print(f"\n[bold blue]üìö –î–∂–µ—Ä–µ–ª–∞ ({len(response.sources)}):[/bold blue]")
    for i, src in enumerate(response.sources, 1):
        console.print(f"[cyan]{i}.[/cyan] Score: {src.score:.3f}")
        console.print(f"   {src.chunk.text[:100]}...\n")

    # –ú–µ—Ç–∞–¥–∞–Ω—ñ
    console.print(f"[dim]‚è±Ô∏è  –ß–∞—Å: {response.metadata.get('duration_seconds')}s[/dim]")


def interactive_mode(agent):
    """–Ü–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∏–π —Ä–µ–∂–∏–º –¥—ñ–∞–ª–æ–≥—É"""
    console.print("\n[bold green]ü§ñ –Ü–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∏–π —Ä–µ–∂–∏–º[/bold green]")
    console.print("[dim]–í–≤–µ–¥—ñ—Ç—å 'exit' –∞–±–æ 'quit' –¥–ª—è –≤–∏—Ö–æ–¥—É[/dim]\n")

    while True:
        try:
            question = input("üí¨ –í—ã: ")

            if question.lower() in ["exit", "quit", "–≤–∏—Ö—ñ–¥"]:
                console.print("\n[yellow]üëã –î–æ –ø–æ–±–∞—á–µ–Ω–Ω—è![/yellow]")
                break

            if not question.strip():
                continue

            console.print("\n[yellow]ü§î –û–±—Ä–æ–±–∫–∞...[/yellow]\n")
            response = agent.answer(question)

            console.print("[bold green]ü§ñ –ê—Å–∏—Å—Ç–µ–Ω—Ç:[/bold green]")
            console.print(Markdown(response.answer))
            console.print()

        except KeyboardInterrupt:
            console.print("\n[yellow]üëã –î–æ –ø–æ–±–∞—á–µ–Ω–Ω—è![/yellow]")
            break
        except Exception as e:
            console.print(f"[red]–ü–æ–º–∏–ª–∫–∞: {e}[/red]\n")


def main():
    parser = argparse.ArgumentParser(description="RAG System")
    parser.add_argument(
        "--mode",
        choices=["index", "query", "interactive"],
        default="interactive",
        help="–†–µ–∂–∏–º —Ä–æ–±–æ—Ç–∏",
    )
    parser.add_argument(
        "--data-dir", default="data/raw", help="–î–∏—Ä–µ–∫—Ç–æ—Ä—ñ—è –∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏"
    )
    parser.add_argument("--question", help="–ó–∞–ø–∏—Ç–∞–Ω–Ω—è (–¥–ª—è mode=query)")

    args = parser.parse_args()

    console.print("[bold blue]üöÄ RAG System[/bold blue]\n")

    # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ñ–≤
    console.print("‚öôÔ∏è  –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ñ–≤...")

    preprocessor = PreprocessorFactory.create(worker="minimal", default_parser="auto")

    embedder = EmbedderFactory.create(
        method="sbert",
        model_name=os.getenv(
            "EMBEDDER_MODEL", "sentence-transformers/all-MiniLM-L6-v2"
        ),
        batch_size=int(os.getenv("EMBEDDER_BATCH_SIZE", 32)),
    )

    storage = FAISSStorage(dimension=384)

    if args.mode == "index":
        # –†–µ–∂–∏–º —ñ–Ω–¥–µ–∫—Å–∞—Ü—ñ—ó
        index_documents(preprocessor, embedder, storage, args.data_dir)

    else:
        # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ —ñ—Å–Ω—É—é—á–∏–π —ñ–Ω–¥–µ–∫—Å
        index_path = "data/indexes/knowledge_base"
        if not Path(f"{index_path}.faiss").exists():
            console.print(
                "[red]‚ùå –Ü–Ω–¥–µ–∫—Å –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ! –°–ø–æ—á–∞—Ç–∫—É –∑–∞–ø—É—Å—Ç—ñ—Ç—å --mode index[/red]"
            )
            return

        console.print("üíæ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —ñ–Ω–¥–µ–∫—Å—É...")
        storage.load(index_path)

        # –°—Ç–≤–æ—Ä—é—î–º–æ LLM client
        api_key = os.getenv("PERPLEXITY_API_KEY")
        if not api_key:
            console.print("[red]‚ùå PERPLEXITY_API_KEY –Ω–µ –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ![/red]")
            return

        llm_client = LLMClientFactory.create(
            provider=os.getenv("LLM_PROVIDER", "perplexity"),
            api_key=api_key,
            model=os.getenv("LLM_MODEL", "sonar"),
        )

        # –°—Ç–≤–æ—Ä—é—î–º–æ AI Agent
        agent = AIAgent(
            storage=storage,
            embedder=embedder,
            llm_client=llm_client,
            top_k=int(os.getenv("TOP_K", 4)),
            min_similarity=float(os.getenv("MIN_SIMILARITY", 0.3)),
            temperature=float(os.getenv("LLM_TEMPERATURE", 0.1)),
            max_tokens=int(os.getenv("LLM_MAX_TOKENS", 800)),
            language="uk",
        )

        console.print("[green]‚úÖ –°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞![/green]\n")

        if args.mode == "query":
            # –†–µ–∂–∏–º –æ–¥–∏–Ω–æ—á–Ω–æ–≥–æ –∑–∞–ø–∏—Ç—É
            if not args.question:
                args.question = input("üí¨ –í–∞—à–µ –∑–∞–ø–∏—Ç–∞–Ω–Ω—è: ")
            query_mode(agent)
        else:
            # –Ü–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∏–π —Ä–µ–∂–∏–º
            interactive_mode(agent)


if __name__ == "__main__":
    main()
